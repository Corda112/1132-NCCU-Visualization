#!/usr/bin/env python3
"""
Twitteræ¨æ–‡è³‡æ–™è™•ç†ä¸»ç¨‹å¼
å®Œæ•´çš„è³‡æ–™æ¸…æ´—å’Œé è™•ç†æµç¨‹ï¼ŒåŒ…å«å…­å€‹å°ˆæ¥­è™•ç†æ­¥é©Ÿ

ä½¿ç”¨æ–¹æ³•:
    python process_twitter_data.py --help                    # é¡¯ç¤ºå¹«åŠ©
    python process_twitter_data.py --all                     # è™•ç†æ‰€æœ‰æª”æ¡ˆ
    python process_twitter_data.py --files file1.json file2.json  # è™•ç†æŒ‡å®šæª”æ¡ˆ
    python process_twitter_data.py --validate                # é©—è­‰è¨­å®š
    python process_twitter_data.py --sample                  # è™•ç†æ¨£æœ¬æª”æ¡ˆæ¸¬è©¦
"""

import argparse
import sys
import json
from pathlib import Path
from typing import List, Optional

# æ·»åŠ é …ç›®æ ¹ç›®éŒ„åˆ°Pythonè·¯å¾‘
sys.path.insert(0, str(Path(__file__).parent))

from data_processing import load_config, setup_logging, DataProcessor


def setup_argument_parser() -> argparse.ArgumentParser:
    """è¨­å®šå‘½ä»¤è¡Œåƒæ•¸è§£æå™¨"""
    parser = argparse.ArgumentParser(
        description="Twitteræ¨æ–‡è³‡æ–™è™•ç†å·¥å…· - å°ˆæ¥­æ–‡æœ¬æ¸…æ´—èˆ‡é è™•ç†",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ç¯„ä¾‹ç”¨æ³•:
  python process_twitter_data.py --all                        # è™•ç†æ‰€æœ‰rawè³‡æ–™
  python process_twitter_data.py --files 20241201*.json      # è™•ç†ç‰¹å®šæª”æ¡ˆ
  python process_twitter_data.py --validate                   # é©—è­‰ç³»çµ±è¨­å®š
  python process_twitter_data.py --sample --limit 100        # è™•ç†æ¨£æœ¬è³‡æ–™
  python process_twitter_data.py --all --workers 4           # ä½¿ç”¨4å€‹åŸ·è¡Œç·’
  python process_twitter_data.py --all --no-metadata         # ä¸ä¿ç•™åŸå§‹metadata

è™•ç†çµæœå°‡å„²å­˜åˆ° DATA/processed/ ç›®éŒ„
å“è³ªå ±å‘Šå°‡è‡ªå‹•ç”Ÿæˆä¸¦é¡¯ç¤ºè™•ç†çµ±è¨ˆ
        """
    )
    
    # ä¸»è¦æ“ä½œé¸é …
    main_group = parser.add_mutually_exclusive_group(required=True)
    main_group.add_argument(
        "--all", 
        action="store_true",
        help="è™•ç†æ‰€æœ‰rawè³‡æ–™æª”æ¡ˆ"
    )
    main_group.add_argument(
        "--files", 
        nargs="+", 
        metavar="FILE",
        help="æŒ‡å®šè¦è™•ç†çš„æª”æ¡ˆåç¨±ï¼ˆæ”¯æ´è¬ç”¨å­—å…ƒï¼‰"
    )
    main_group.add_argument(
        "--validate", 
        action="store_true",
        help="é©—è­‰ç³»çµ±è¨­å®šå’Œä¾è³´"
    )
    main_group.add_argument(
        "--sample",
        action="store_true", 
        help="è™•ç†æ¨£æœ¬è³‡æ–™é€²è¡Œæ¸¬è©¦"
    )
    
    # è™•ç†é¸é …
    parser.add_argument(
        "--config",
        type=str,
        default="data_processing/config.yaml",
        help="é…ç½®æª”æ¡ˆè·¯å¾‘ (é è¨­: data_processing/config.yaml)"
    )
    parser.add_argument(
        "--workers",
        type=int,
        help="ä¸¦è¡Œè™•ç†åŸ·è¡Œç·’æ•¸é‡ (è¦†è“‹é…ç½®æª”æ¡ˆè¨­å®š)"
    )
    parser.add_argument(
        "--no-metadata",
        action="store_true",
        help="ä¸ä¿ç•™åŸå§‹æ¨æ–‡metadataä»¥ç¯€çœç©ºé–“"
    )
    parser.add_argument(
        "--limit",
        type=int,
        help="é™åˆ¶è™•ç†çš„æª”æ¡ˆæ•¸é‡ï¼ˆç”¨æ–¼æ¸¬è©¦ï¼‰"
    )
    parser.add_argument(
        "--output-dir",
        type=str,
        help="è‡ªè¨‚è¼¸å‡ºç›®éŒ„ï¼ˆè¦†è“‹é…ç½®æª”æ¡ˆè¨­å®šï¼‰"
    )
    
    # æ—¥èªŒé¸é …
    parser.add_argument(
        "--verbose", "-v",
        action="store_true",
        help="é¡¯ç¤ºè©³ç´°æ—¥èªŒ"
    )
    parser.add_argument(
        "--quiet", "-q",
        action="store_true", 
        help="åªé¡¯ç¤ºéŒ¯èª¤è¨Šæ¯"
    )
    
    return parser


def validate_dependencies():
    """æª¢æŸ¥å¿…è¦çš„ä¾è³´åŒ…"""
    missing_deps = []
    
    try:
        import spacy
        # æª¢æŸ¥spaCyæ¨¡å‹
        try:
            nlp = spacy.load("en_core_web_sm")
        except OSError:
            print("âŒ spaCyè‹±æ–‡æ¨¡å‹æœªå®‰è£")
            print("è«‹åŸ·è¡Œ: python -m spacy download en_core_web_sm")
            return False
    except ImportError:
        missing_deps.append("spacy")
    
    try:
        import emoji
    except ImportError:
        missing_deps.append("emoji")
    
    try:
        import orjson
    except ImportError:
        missing_deps.append("orjson")
    
    try:
        import yaml
    except ImportError:
        missing_deps.append("pyyaml")
    
    try:
        import tqdm
    except ImportError:
        missing_deps.append("tqdm")
    
    if missing_deps:
        print(f"âŒ ç¼ºå°‘å¿…è¦ä¾è³´: {', '.join(missing_deps)}")
        print("è«‹åŸ·è¡Œ: pip install -r requirements.txt")
        return False
    
    print("âœ… æ‰€æœ‰ä¾è³´æª¢æŸ¥é€šé")
    return True


def setup_spacy_model():
    """è¨­å®šspaCyæ¨¡å‹"""
    try:
        import spacy
        print("ğŸ“¥ æ­£åœ¨è¼‰å…¥spaCyæ¨¡å‹...")
        nlp = spacy.load("en_core_web_sm")
        print("âœ… spaCyæ¨¡å‹è¼‰å…¥æˆåŠŸ")
        return True
    except OSError:
        print("âŒ æ‰¾ä¸åˆ°spaCyè‹±æ–‡æ¨¡å‹")
        print("æ­£åœ¨å˜—è©¦ä¸‹è¼‰...")
        try:
            import subprocess
            result = subprocess.run([
                sys.executable, "-m", "spacy", "download", "en_core_web_sm"
            ], capture_output=True, text=True)
            
            if result.returncode == 0:
                print("âœ… spaCyæ¨¡å‹ä¸‹è¼‰æˆåŠŸ")
                return True
            else:
                print(f"âŒ spaCyæ¨¡å‹ä¸‹è¼‰å¤±æ•—: {result.stderr}")
                return False
        except Exception as e:
            print(f"âŒ è‡ªå‹•ä¸‹è¼‰å¤±æ•—: {e}")
            print("è«‹æ‰‹å‹•åŸ·è¡Œ: python -m spacy download en_core_web_sm")
            return False


def expand_file_patterns(patterns: List[str], base_dir: Path) -> List[str]:
    """å±•é–‹æª”æ¡ˆåŒ¹é…æ¨¡å¼"""
    expanded_files = []
    
    for pattern in patterns:
        if '*' in pattern or '?' in pattern:
            # è¬ç”¨å­—å…ƒåŒ¹é…
            matched_files = list(base_dir.glob(pattern))
            expanded_files.extend([f.name for f in matched_files])
        else:
            # ç›´æ¥æª”æ¡ˆå
            expanded_files.append(pattern)
    
    return list(set(expanded_files))  # å»é‡


def display_processing_header():
    """é¡¯ç¤ºè™•ç†é–‹å§‹çš„æ¨™é¡Œ"""
    print("\n" + "="*70)
    print("ğŸš€ Twitteræ¨æ–‡è³‡æ–™è™•ç†ç³»çµ±")
    print("="*70)
    print("ğŸ“‹ è™•ç†æµç¨‹:")
    print("   1ï¸âƒ£  è½‰å°å¯« & éæ¿¾è½‰æ¨")
    print("   2ï¸âƒ£  ç§»é™¤URL/Mentionï¼Œä¿ç•™Hashtag") 
    print("   3ï¸âƒ£  Emojiè½‰æ›ç‚ºæ–‡å­—æè¿°")
    print("   4ï¸âƒ£  è‡ªè¨‚æ–·è©ï¼ˆä¿ç•™$BTCç­‰ç¬¦è™Ÿï¼‰")
    print("   5ï¸âƒ£  åœç”¨è©éæ¿¾")
    print("   6ï¸âƒ£  è©å½¢é‚„åŸ")
    print("="*70)


def display_results_summary(results: dict):
    """é¡¯ç¤ºè™•ç†çµæœæ‘˜è¦"""
    if "error" in results:
        print(f"\nâŒ è™•ç†å¤±æ•—: {results['error']}")
        return
    
    summary = results.get("processing_summary", {})
    print(f"\nğŸ“Š è™•ç†å®Œæˆæ‘˜è¦:")
    print(f"   ğŸ“ è™•ç†æª”æ¡ˆ: {summary.get('successful_files', 0)}/{summary.get('total_files', 0)}")
    print(f"   ğŸ“ è™•ç†æ¨æ–‡: {summary.get('total_tweets_input', 0):,} â†’ {summary.get('total_tweets_output', 0):,}")
    print(f"   â±ï¸  ç¸½è™•ç†æ™‚é–“: {summary.get('total_processing_time', 0):.2f}ç§’")
    
    if summary.get('failed_files', 0) > 0:
        print(f"   âš ï¸  å¤±æ•—æª”æ¡ˆ: {len(results.get('failed_files', []))}")
    
    # é¡¯ç¤ºå“è³ªçµ±è¨ˆ
    quality = results.get("quality_summary", {})
    if quality and "overall_statistics" in quality:
        stats = quality["overall_statistics"]
        print(f"\nğŸ“ˆ å“è³ªçµ±è¨ˆ:")
        print(f"   âœ… æˆåŠŸç‡: {stats.get('successful_rate', 0):.2%}")
        print(f"   ğŸ”„ è½‰æ¨éæ¿¾: {stats.get('retweet_rate', 0):.2%}")
        print(f"   âŒ éŒ¯èª¤ç‡: {stats.get('error_rate', 0):.2%}")


def main():
    """ä¸»ç¨‹å¼å…¥å£"""
    parser = setup_argument_parser()
    args = parser.parse_args()
    
    # æª¢æŸ¥ä¾è³´
    if not validate_dependencies():
        sys.exit(1)
    
    # é©—è­‰æ¨¡å¼
    if args.validate:
        print("ğŸ” ç³»çµ±é©—è­‰æ¨¡å¼")
        
        # æª¢æŸ¥spaCyæ¨¡å‹
        if not setup_spacy_model():
            sys.exit(1)
        
        # è¼‰å…¥é…ç½®
        try:
            config = load_config(args.config)
            print("âœ… é…ç½®æª”æ¡ˆè¼‰å…¥æˆåŠŸ")
        except Exception as e:
            print(f"âŒ é…ç½®æª”æ¡ˆè¼‰å…¥å¤±æ•—: {e}")
            sys.exit(1)
        
        # è¨­å®šæ—¥èªŒ
        logger = setup_logging(config)
        
        # åˆå§‹åŒ–è™•ç†å™¨ä¸¦é©—è­‰
        try:
            processor = DataProcessor(config)
            validation_results = processor.validate_processing_setup()
            
            print("\nğŸ“‹ ç³»çµ±é©—è­‰çµæœ:")
            
            # ç›®éŒ„æª¢æŸ¥
            dirs = validation_results["directories"]
            for name, status in dirs.items():
                icon = "âœ…" if status["exists"] and status["is_directory"] else "âŒ"
                print(f"   {icon} {name}: {status}")
            
            # æ–‡æœ¬æ¸…æ´—å™¨æª¢æŸ¥
            cleaner = validation_results["text_cleaner"]
            if cleaner.get("validation_failed"):
                print(f"   âŒ æ–‡æœ¬æ¸…æ´—å™¨: {cleaner.get('error')}")
            else:
                success_count = sum(1 for v in cleaner.values() if v is True)
                print(f"   âœ… æ–‡æœ¬æ¸…æ´—å™¨: {success_count}/{len(cleaner)} æ¸¬è©¦é€šé")
            
            # æ¨£æœ¬è™•ç†æª¢æŸ¥
            sample = validation_results["sample_processing"]
            if sample["success"]:
                print("   âœ… æ¨£æœ¬è™•ç†: æˆåŠŸ")
            else:
                print(f"   âŒ æ¨£æœ¬è™•ç†: {sample.get('error', 'å¤±æ•—')}")
            
            print("\nğŸ‰ ç³»çµ±é©—è­‰å®Œæˆ!")
            
        except Exception as e:
            print(f"âŒ é©—è­‰éç¨‹ç™¼ç”ŸéŒ¯èª¤: {e}")
            sys.exit(1)
        
        return
    
    # ç¢ºä¿spaCyæ¨¡å‹å¯ç”¨
    if not setup_spacy_model():
        sys.exit(1)
    
    # è¼‰å…¥é…ç½®
    try:
        config = load_config(args.config)
    except Exception as e:
        print(f"âŒ é…ç½®æª”æ¡ˆè¼‰å…¥å¤±æ•—: {e}")
        sys.exit(1)
    
    # èª¿æ•´é…ç½®ï¼ˆæ ¹æ“šå‘½ä»¤è¡Œåƒæ•¸ï¼‰
    if args.workers:
        config["processing"]["performance"]["max_workers"] = args.workers
    
    if args.output_dir:
        config["processing"]["paths"]["processed_data"] = args.output_dir
    
    if args.verbose:
        config["logging"]["level"] = "DEBUG"
    elif args.quiet:
        config["logging"]["level"] = "ERROR"
    
    # è¨­å®šæ—¥èªŒ
    logger = setup_logging(config)
    
    # é¡¯ç¤ºè™•ç†æ¨™é¡Œ
    display_processing_header()
    
    # åˆå§‹åŒ–è™•ç†å™¨
    try:
        processor = DataProcessor(config)
    except Exception as e:
        print(f"âŒ è™•ç†å™¨åˆå§‹åŒ–å¤±æ•—: {e}")
        sys.exit(1)
    
    # åŸ·è¡Œè™•ç†ä»»å‹™
    results = None
    preserve_metadata = not args.no_metadata
    
    try:
        if args.all:
            print("ğŸ“ è™•ç†æ‰€æœ‰rawè³‡æ–™æª”æ¡ˆ...")
            results = processor.quick_process_all()
            
        elif args.files:
            # å±•é–‹æª”æ¡ˆæ¨¡å¼
            raw_dir = Path(config["processing"]["paths"]["raw_data"])
            expanded_files = expand_file_patterns(args.files, raw_dir)
            
            if args.limit:
                expanded_files = expanded_files[:args.limit]
            
            print(f"ğŸ“ è™•ç†æŒ‡å®šæª”æ¡ˆ: {len(expanded_files)} å€‹æª”æ¡ˆ")
            results = processor.process_specific_files(expanded_files)
            
        elif args.sample:
            # æ¨£æœ¬è™•ç†æ¨¡å¼
            raw_dir = Path(config["processing"]["paths"]["raw_data"])
            sample_files = list(raw_dir.glob("*.json"))
            
            if not sample_files:
                print("âŒ æ²’æœ‰æ‰¾åˆ°æ¨£æœ¬æª”æ¡ˆ")
                sys.exit(1)
            
            # é™åˆ¶æ¨£æœ¬æª”æ¡ˆæ•¸é‡
            limit = args.limit or 2
            sample_files = sample_files[:limit]
            
            print(f"ğŸ§ª æ¨£æœ¬è™•ç†æ¨¡å¼: {len(sample_files)} å€‹æª”æ¡ˆ")
            results = processor.process_specific_files([f.name for f in sample_files])
        
        # é¡¯ç¤ºçµæœ
        if results:
            display_results_summary(results)
            
            # å„²å­˜è™•ç†çµ±è¨ˆ
            output_dir = Path(config["processing"]["paths"]["processed_data"])
            stats_file = output_dir / f"processing_stats_{results['generated_at'][:10]}.json"
            
            try:
                with open(stats_file, 'w', encoding='utf-8') as f:
                    json.dump(results, f, ensure_ascii=False, indent=2, default=str)
                print(f"\nğŸ“Š è©³ç´°çµ±è¨ˆå·²å„²å­˜è‡³: {stats_file}")
            except Exception as e:
                logger.warning(f"çµ±è¨ˆæª”æ¡ˆå„²å­˜å¤±æ•—: {e}")
        
    except KeyboardInterrupt:
        print("\nâš ï¸ è™•ç†è¢«ç”¨æˆ¶ä¸­æ–·")
        sys.exit(1)
    except Exception as e:
        print(f"\nâŒ è™•ç†éç¨‹ç™¼ç”ŸéŒ¯èª¤: {e}")
        logger.exception("è™•ç†éŒ¯èª¤è©³æƒ…")
        sys.exit(1)
    
    print("\nğŸ‰ æ‰€æœ‰ä»»å‹™å®Œæˆ!")


if __name__ == "__main__":
    main() 